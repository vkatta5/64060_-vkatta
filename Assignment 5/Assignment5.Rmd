---
title: "Assignment - 5"
author: "Vamshee Deepak Goud Katta"
date: "11/29/2021"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

set.seed(123)

library(cluster)
library(caret)
library(dendextend)
library(knitr)
library(factoextra)

```


### Importing dataset(Cereals)

```{r}

library(readr)
Cereals <- read_csv("Cereals.csv", col_types = cols(calories = col_number(), 
                                                    protein = col_number(), fat = col_number(), 
                                                    sodium = col_number(), fiber = col_number(), 
                                                    carbo = col_number(), sugars = col_number(), 
                                                    potass = col_number(), vitamins = col_number(), 
                                                    shelf = col_number(), weight = col_number(), 
                                                    cups = col_number(), rating = col_number()))

Cereals1 <- data.frame(Cereals[,4:16])

```

## Pre-processing data and normalizing the data

```{r}

Cereals1 <- na.omit(Cereals1)
Cereals2 <- scale(Cereals1)

```

## Applying  hierarchical clustering to the data using Euclidean distance to the normalized measurements.

### Calculating Dissimilarity Matrix and performing Hierarchial Clustering.

```{r}

Euclidian <- dist(Cereals2, method = "euclidean")

## Clustering the Cereals dataset.

Complete <- hclust(Euclidian, method = "complete")

## Plotting the dendogram.

plot(Complete, cex = 0.7, hang = -1)

```

### Using Agnes to compare the clustering.

```{r}

# Single Linkage Method
Single <- agnes(Cereals2, method = "single")
# Complete Linkage Method
Complete1 <- agnes(Cereals2, method = "complete")
# Average Linkage Method
Average <- agnes(Cereals2, method = "average")
# Ward Method
Ward <- agnes(Cereals2, method = "ward")

```

### Comparing the agglomerative coefficients.
### Single Linkage vs Complete Linkage vs Average Linkage vs Ward.

```{r}

print(Single$ac)
print(Complete1$ac)
print(Average$ac)
print(Ward$ac)

```

### Here we can see that Ward method is best with highest value of 0.9046042.

### Choosing the clusters:

### Plotting the agnes using ward method and cutting the Dendogram.
### We will take 5 clusters (k = 5) based on the distance.

```{r}

pltree(Ward, cex = 0.7, hang = -1, main = "Agnes using Ward")
rect.hclust(Ward, k = 5, border = 1:4)
Cluster <- cutree(Ward, k=5)
Cluster1 <- as.data.frame(cbind(Cereals2, Cluster))

```

### Structure of the clusters and their stability.

### Creating Partitions.

```{r}

PartA <- Cereals1[1:50,]
PartB <- Cereals1[51:74,]

```

### Performing Hierarchial Clustering, plotting and cutting the dendogram with k=5.

```{r}

# Single Linkage Method of Part A
Single1 <- agnes(scale(PartA), method = "single")
# Complete Linkage Method of Part A
Complete2 <- agnes(scale(PartA), method = "complete")
# Average Linkage Method of Part A
Average1 <- agnes(scale(PartA), method = "average")
# Ward Method of Part A
Ward1 <- agnes(scale(PartA), method = "ward")

cbind(Single= Single1$ac , Complete=Complete2$ac , Average= Average1$ac , Ward= Ward1$ac)
pltree(Ward1, cex = 0.7, hang = -1, main = "Agnes with partitioned data using Ward")
# Clustering Part A of the data set
rect.hclust(Ward1, k = 5, border = 1:4)
# Cutting the dendrogram
Cluster2 <- cutree(Ward1, k = 5)

```

### Calculating the centeroids.

```{r}

Centroids <- as.data.frame(cbind(PartA, Cluster2))
Centroids[Centroids$Cluster2==1,]
# Centroid 1
centroid1 <- colMeans(Centroids[Centroids$Cluster2==1,])
Centroids[Centroids$Cluster2==2,]
# Centroid 2
centroid2 <- colMeans(Centroids[Centroids$Cluster2==2,])
Centroids[Centroids$Cluster2==3,]
# Centroid 3
centroid3 <- colMeans(Centroids[Centroids$Cluster2==3,])
Centroids[Centroids$Cluster2==4,]
# Centroid 4
centroid4 <- colMeans(Centroids[Centroids$Cluster2==4,])
Centroids1 <- rbind(centroid1, centroid2, centroid3, centroid4)
Centroids2 <- as.data.frame(rbind(Centroids[,-14], PartB))

```

### Calculating the Distance.

```{r}
Distance <- get_dist(Centroids2)
Matrix <- as.matrix(Distance)
Distance1 <- data.frame(data=seq(1,nrow(PartB),1), Clusters = rep(0,nrow(PartB)))
for(i in 1:nrow(PartB)) 
  {Distance1[i,2] <- which.min(Matrix[i+4, 1:4])}
Distance1

cbind(Cluster1$Cluster[51:74], Distance1$Clusters)
# Tabulating the results
table(Cluster1$Cluster[51:74] == Distance1$Clusters)

```


### We are getting 12 FALSE and 12 TRUE, so we can conclude that the model is partially stable.

### Finding a cluster of “healthy cereals.”

### Clustering Healthy Cereals

```{r, results='hide'}

Healthy <- Cereals
Healthy <- na.omit(Healthy)
Healthy1 <- cbind(Healthy, Cluster)
Healthy1[Healthy1$Cluster==1,]
Healthy1[Healthy1$Cluster==2,]
Healthy1[Healthy1$Cluster==3,]
Healthy1[Healthy1$Cluster==4,]

```

#### Mean ratings to determine the best cluster.

```{r}

mean(Healthy1[Healthy1$Cluster==1,"rating"])
mean(Healthy1[Healthy1$Cluster==2,"rating"])
mean(Healthy1[Healthy1$Cluster==3,"rating"])
mean(Healthy1[Healthy1$Cluster==4,"rating"])

```

### As we can se that the mean rating of the cluster 1 is the highest(i.e. 73.84446), we will choose cluster 1.
