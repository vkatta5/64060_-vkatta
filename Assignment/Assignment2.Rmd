---
title: "Assignment 2"
author: "Vamshee Deepak Goud Katta"
date: "10/2/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Inserting Data and Libraries

# Reading the UniversalBank csv file and inserting approproate libraries

```{r}

library(class)
library(caret)
library(ISLR)
library(dummies)
library(dplyr)
library(tidyr)
library(ggplot2)

UBank_data <- read.csv("UniversalBank.csv")

```

## 2. Data Cleaning and Splitting

# Removing the ID and Zipcode columns from the Bank_data dataset
# Converting Education column into factor and creating a dummy database of Bank_data
# Moving personal.loan column to the first column position

```{r}

library(caret)
library(class)
library(ISLR)
library(tidyr)
library(dummies)
library(dplyr)
library(ggplot2)

UBank_data$Education = as.factor(UBank_data$Education)
UBank_data$Personal.Loan = as.factor(UBank_data$Personal.Loan)
UBank_data_d = dummy.data.frame(select(UBank_data, -c(ZIP.Code,ID)))

n <- which(colnames(UBank_data_d)=="Personal.Loan1")
Personal.Loan <- UBank_data_d$Personal.Loan1
UBank_data_d <- cbind(Personal.Loan, UBank_data_d[, -n])
UBank_data_d <- UBank_data_d[,-11]

head(UBank_data_d)

```

## 3. Data Partition

# Partitioning the UniversalBank dataset into Training and validation sets

```{r}

set.seed(123)
Index_Train <- createDataPartition(UBank_data_d$Personal.Loan, p=0.6, list = FALSE) 
# 60% of data is taken as Training Data

Train <- UBank_data_d[Index_Train,]
Validation <- UBank_data_d[-Index_Train,] 
# Rest of the data is taken as Validation Data

summary(Train)
summary(Validation)

```

## 4. Q1. Classifying customer using given constraints

# Creating Test data from Q1 in Assignment
# Normalizing the Training Data
# Applying KNN Model with k=1

```{r}

# copying data

Train_norm <- Train
Validation_norm <- Validation
UBD_norm <- UBank_data_d

#Creating test data from the question

Test1 <- data.frame(Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education1 = 0, Education2 = 1, Education3 = 0, Mortgage = 0, Securities.Account = 0, CD.Account = 0, Online = 1, CreditCard = 1)

#Normalizing the data

Test_norm1 <- Test1

norm_values <- preProcess(Train, method = c("center", "scale"))
Train_norm <- predict(norm_values, Train)
Validation_norm <- predict(norm_values, Validation)
UBD_norm <- predict(norm_values, UBank_data_d)

#combine normalized values of train and validation and then preprocess and normalize test data#############

summary(Train_norm)
var(Train_norm)
summary(Validation_norm)
var(Validation_norm)

# Applying KNN Model on test data

Q1_KNN <- knn(train = Train_norm[,-10], test = Test1, cl = Train[,1], k=1, prob = 0.5)
Q1.attributes<- attributes(Q1_KNN)
row.names(Train_norm)[attr(Q1_KNN, "Q1_KNN.index")]
Q1.attributes[1]
Q1.attributes[3]

```
## 5. Training the KNN Model

# Combining training and validation datasets and renormalizing data
# Expanding search grid to appropriate K value to gain highest possible accuracy

```{r}

set.seed(123)
Search_grid <- expand.grid(k=c(2,3,5,7,14))
Model <- train(Personal.Loan~Income+Mortgage, data =UBD_norm, method = "knn", tuneGrid=Search_grid, preProcess='range')
head(Model)

```

## 7. Q3. Creating Confusion Matrix

```{r}

Train_Predictors <- Train_norm
Test_Predictors <- Validation

Train_labels <-Train_norm[,1]
Test_labels  <-Validation_norm[,1]

Predicted_Test_labels <- knn(Train_Predictors, Test_Predictors, cl=Train_labels, k=1, prob = TRUE)
library(gmodels)
CrossTable(x=Test_labels, y=Predicted_Test_labels, prop.chisq = FALSE)

```

## 8. Q4. Classifying customer using best K

```{r}
Q4_KNN <- knn(Train_norm[,2:14], Test1, cl = Train[,1], k=3, prob = TRUE)
head(Q4_KNN)
```

## 9. Q5. Repartitioning data into 5:3:2

```{r}

set.seed(123)
Index_Train2 <- createDataPartition(UBank_data_d$Personal.Loan, p=0.5, list = FALSE) 
# 50% of data is taken as Training Data

Train2 <- UBank_data_d[Index_Train2,]
Validation.test <- UBank_data_d[-Index_Train2,] 
# Rest of the data is taken as Validation and Test Data
Index_Validation <- createDataPartition(Validation.test$Personal.Loan, p=0.6, list = FALSE)
# 30% of total or 60% of remaining data is taken as Validation Data
Validation2 <- Validation.test[Index_Validation,]
Test2 <- Validation.test[-Index_Validation,]

knn12 <- knn(train=Train2, test=Train2,cl=Train2[,1], k=3 ,prob=TRUE)
head(knn12)

```

## 10. Normalizing the data

```{r}
Train_norm2 <- Train2
Validation_norm2 <- Validation2
Test_norm2 <- Test2

norm_values2 <- preProcess(Train2, method = c("center", "scale"))
Train_norm2 <- predict(norm_values2, Train2)
Validation_norm2 <- predict(norm_values2, Validation2)

summary(Train_norm2)
var(Train_norm2)
summary(Validation_norm2)
var(Validation_norm2)

```

## 11. Combining Train2 and Validation2 datasets to renormalize

# Re-normalizing the combined data

```{r}

ForTest_norm2 <- rbind.data.frame(Train_norm2, Validation_norm2, deparse.level = 1, make.row.names = T, stringsAsFactors = F, factor.exclude = T)

norm_values3 <- preProcess(ForTest_norm2, method = c("center", "scale"))
Test_norm2 <- predict(norm_values3, ForTest_norm2)

head(Test_norm2)
var(Test_norm2)

```

## 12. Applying KNN Method with the best K

```{r}

Q5_KNN <- knn(Train_norm2, Validation_norm2, cl = Train2[,1], k=3, prob = TRUE)
head(Q5_KNN)
row.names(Train_norm2)[attr(Q5_KNN, "Q5_KNN.index")]

```

## 13. Creating Confusion Matrix 2

```{r}

Train_Predictors <- Train_norm2
Test_Predictors <- Validation_norm2

Train_labels2 <-Train_norm2[,1]
Test_labels2  <-Validation_norm2[,1]

Predicted_Test_labels2 <- knn(Train_Predictors, Test_Predictors, cl=Train_labels2, k=1, prob = TRUE)
library(gmodels)
CrossTable(x=Test_labels2, y=Predicted_Test_labels2, prop.chisq = FALSE)
class_prob<-attr(Predicted_Test_labels, 'prob')
head(class_prob)

```

## 14. Creating Confusion Matrix 3

```{r}

Train_Predictors <- ForTest_norm2
Test_Predictors <- Test_norm2

Train_labels3 <-ForTest_norm2[,1]
Test_labels3  <-Test_norm2[,1]

Predicted_Test_labels3 <- knn(Train_Predictors, Test_Predictors, cl=Train_labels3, k=1, prob = TRUE)
library(gmodels)
CrossTable(x=Test_labels3, y=Predicted_Test_labels3, prop.chisq = FALSE)
class_prob<-attr(Predicted_Test_labels3, 'prob')
head(class_prob)

```



